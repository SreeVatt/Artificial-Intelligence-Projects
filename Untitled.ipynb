{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20a998a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sreev\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.models import load_model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pathlib\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18771953",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDirectory = '../input/fruit-recognition/train/train'\n",
    "\n",
    "# creating black image\n",
    "\n",
    "imageHeight = 100\n",
    "imageWidth = 100\n",
    "thickness = 3\n",
    "inputShape = (imageHeight, imageWidth, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fd15be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageDataGenerator = ImageDataGenerator(rescale=1./255,\n",
    "                                vertical_flip=True,\n",
    "                                horizontal_flip=True,\n",
    "                                rotation_range=40,\n",
    "                                width_shift_range=0.2,\n",
    "                                height_shift_range=0.2,\n",
    "                                zoom_range=0.1,\n",
    "                                validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e658e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataGenerator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156c82f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGenerator = imageDataGenerator.flow_from_directory(trainDirectory,\n",
    "                                                 shuffle=True,\n",
    "                                                 batch_size=32,\n",
    "                                                 subset='training',\n",
    "                                                 target_size=(100, 100))\n",
    "\n",
    "validGenerator = imageDataGenerator.flow_from_directory(trainDirectory,\n",
    "                                                 shuffle=True,\n",
    "                                                 batch_size=16,\n",
    "                                                 subset='validation',\n",
    "                                                 target_size=(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53a9cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (5, 5), activation='relu', padding='Same', input_shape=inputShape))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', padding='Same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='Same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='Same'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(33, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-4), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504ea06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, mode='max',\n",
    "                                     restore_best_weights=True)\n",
    "history = model.fit(trainGenerator, validation_data=validGenerator,\n",
    "                   steps_per_epoch=trainGenerator.n//trainGenerator.batch_size,\n",
    "                    validation_steps=validGenerator.n//validGenerator.batch_size,\n",
    "                    callbacks=[early],\n",
    "                   epochs=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b07145",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_CNN_saved')\n",
    "model = load_model('model_CNN_saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6146311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759bc89a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aae109",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruitMap = dict([(v, k) for k, v in trainGenerator.class_indices.items()])\n",
    "fruitMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad16ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loading image from file system\n",
    "samplePath = pathlib.Path(\"../input/fruit-recognition/train/train/Apple Braeburn/Apple Braeburn_100.jpg\")\n",
    "\n",
    "# load_img(): function from the Keras library that loads the image file as a PIL (Python Imaging Library) image and resize it to a target size of (100, 100) pixels.\n",
    "\n",
    "image = tf.keras.preprocessing.image.load_img(\n",
    "    samplePath, target_size=(100, 100)\n",
    ")\n",
    "\n",
    "# displaying the image using imshow() function.\n",
    "plt.imshow(image)\n",
    "# converting the image to array and normalizes the pixel values to be between 0 and 1 using division by 255.\n",
    "image = np.array(image)\n",
    "image = image / 255.0\n",
    "\n",
    "# The reshape() function is then used to add an extra dimension to the array, corresponding to the batch size.\n",
    "# In this case, the batch size is set to 1, since we are processing only one image at a time and 3 are the RGB Channels of the image.\n",
    "image = image.reshape(1,imageWidth,imageHeight, 3)\n",
    "\n",
    "# Finally, the pre-trained model is used to make a prediction on the input image using the predict() function.\n",
    "# The output of predict() is an array of predicted class probabilities, where each element of the array corresponds to a different class label.\n",
    "predictions = model.predict(image)\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
